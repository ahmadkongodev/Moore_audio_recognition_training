{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc9e721-bd20-40b0-8ab2-da0cefbd5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.image import resize\n",
    "import sounddevice as sd\n",
    "import wavio\n",
    "from tensorflow.keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d015c357-b76b-45ba-bccb-32877cd61058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<librosa.display.AdaptiveWaveplot at 0x20ec26b5700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data, sample_rate=librosa.load(\"DataSet/laafi/65a5a9901647a_170535566465a5a9901a66c.wav\")\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "librosa.display.waveshow(data, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8d5998-3c0b-4423-9a92-b9b09008e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 laafi 291\n",
      "1 nii-yibeugo 248\n",
      "2 nii-zabre 282\n",
      "3 ni-winiga 285\n",
      "4 oub ya laafi 256\n",
      "5 winig-kibare 260\n",
      "6 yibeog-kibare 278\n",
      "7 yika laafi 255\n",
      "8 zabre kibare 248\n",
      "9 zackramba 262\n"
     ]
    }
   ],
   "source": [
    "def extract_features(file_path, n_mfcc=42, max_pad_len=100):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "    pad_width = max_pad_len - mfccs.shape[1]\n",
    "    if pad_width > 0:\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfccs = mfccs[:, :max_pad_len]\n",
    "    return mfccs.T  # Transpose to shape (num_frames, num_mfcc)\n",
    "# Define your folder structure\n",
    "data_path = 'DataSet/'\n",
    "classes = ['laafi', 'nii-yibeugo','nii-zabre', 'ni-winiga', 'oub ya laafi','winig-kibare','yibeog-kibare', 'yika laafi', 'zabre kibare', 'zackramba']\n",
    "dic={}\n",
    "extracted_features = []\n",
    "labels = []\n",
    "c = 0\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    for file_name in os.listdir(class_path):\n",
    "        file_path = os.path.join(class_path, file_name)\n",
    "        try:\n",
    "            features = extract_features(file_path)\n",
    "            extracted_features.append(features)\n",
    "            labels.append(i)\n",
    "            c += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Removing unsupported file: {file_path}\")\n",
    "            os.remove(file_path)\n",
    "    print(i,class_name,c)\n",
    "    dic[class_name]=c\n",
    "    c = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bff8073-a91a-4252-942b-c007ac5ed77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'laafi': 291, 'nii-yibeugo': 248, 'nii-zabre': 282, 'ni-winiga': 285, 'oub ya laafi': 256, 'winig-kibare': 260, 'yibeog-kibare': 278, 'yika laafi': 255, 'zabre kibare': 248, 'zackramba': 262}\n"
     ]
    }
   ],
   "source": [
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddae5b5e-91b1-4ef0-ad40-82cb091fb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(extracted_features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Shuffle and split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=len(classes))\n",
    "y_test = to_categorical(y_test, num_classes=len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6c776d-f106-4d24-aa9b-74ea35ce3d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc42cf-2d7e-443b-8fff-9c1137cf6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# Define the model\n",
    "input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = LSTM(100, return_sequences=True)(input_layer) #512, 256, 128, 100\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "x = LSTM(100)(x) #128\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#f1 score, \n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ca413-7e34-4f5e-9b03-1835f869c51b",
   "metadata": {},
   "source": [
    "### test sur les batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc2fe7d-f279-40c9-aa2f-028f149558e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch size: 16\n",
      "Epoch 1/20\n",
      "134/134 [==============================] - 48s 283ms/step - loss: 3.3018 - accuracy: 0.1083 - val_loss: 2.3152 - val_accuracy: 0.1201\n",
      "Epoch 2/20\n",
      "134/134 [==============================] - 35s 259ms/step - loss: 3.0246 - accuracy: 0.1116 - val_loss: 2.3480 - val_accuracy: 0.1351\n",
      "Epoch 3/20\n",
      "134/134 [==============================] - 36s 270ms/step - loss: 2.7837 - accuracy: 0.1093 - val_loss: 2.3316 - val_accuracy: 0.1182\n",
      "Epoch 4/20\n",
      "134/134 [==============================] - 36s 269ms/step - loss: 2.6417 - accuracy: 0.1220 - val_loss: 2.3327 - val_accuracy: 0.1144\n",
      "Epoch 5/20\n",
      "134/134 [==============================] - 33s 248ms/step - loss: 2.5511 - accuracy: 0.1262 - val_loss: 2.3632 - val_accuracy: 0.1238\n",
      "Epoch 6/20\n",
      "134/134 [==============================] - 36s 265ms/step - loss: 2.4614 - accuracy: 0.1318 - val_loss: 2.2796 - val_accuracy: 0.1538\n",
      "Epoch 7/20\n",
      "134/134 [==============================] - 33s 247ms/step - loss: 2.3967 - accuracy: 0.1356 - val_loss: 2.2318 - val_accuracy: 0.1764\n",
      "Epoch 8/20\n",
      "134/134 [==============================] - 34s 255ms/step - loss: 2.3520 - accuracy: 0.1477 - val_loss: 2.2568 - val_accuracy: 0.1538\n",
      "Epoch 9/20\n",
      "134/134 [==============================] - 32s 235ms/step - loss: 2.3943 - accuracy: 0.1290 - val_loss: 2.2403 - val_accuracy: 0.1632\n",
      "Epoch 10/20\n",
      "134/134 [==============================] - 33s 248ms/step - loss: 2.3077 - accuracy: 0.1492 - val_loss: 2.2816 - val_accuracy: 0.1689\n",
      "Epoch 11/20\n",
      "134/134 [==============================] - 34s 251ms/step - loss: 2.2489 - accuracy: 0.1674 - val_loss: 2.1663 - val_accuracy: 0.1839\n",
      "Epoch 12/20\n",
      "134/134 [==============================] - 32s 241ms/step - loss: 2.1494 - accuracy: 0.1904 - val_loss: 2.1390 - val_accuracy: 0.2083\n",
      "Epoch 13/20\n",
      "134/134 [==============================] - 32s 235ms/step - loss: 2.0622 - accuracy: 0.2275 - val_loss: 2.0037 - val_accuracy: 0.2589\n",
      "Epoch 14/20\n",
      "134/134 [==============================] - 32s 238ms/step - loss: 2.0266 - accuracy: 0.2359 - val_loss: 1.9084 - val_accuracy: 0.2683\n",
      "Epoch 15/20\n",
      "134/134 [==============================] - 32s 241ms/step - loss: 1.9353 - accuracy: 0.2627 - val_loss: 1.8566 - val_accuracy: 0.2702\n",
      "Epoch 16/20\n",
      "134/134 [==============================] - 37s 276ms/step - loss: 1.9089 - accuracy: 0.2636 - val_loss: 1.8700 - val_accuracy: 0.2795\n",
      "Epoch 17/20\n",
      "134/134 [==============================] - 31s 230ms/step - loss: 1.8964 - accuracy: 0.3016 - val_loss: 1.8056 - val_accuracy: 0.3433\n",
      "Epoch 18/20\n",
      "134/134 [==============================] - 34s 250ms/step - loss: 1.8575 - accuracy: 0.2795 - val_loss: 2.2781 - val_accuracy: 0.2308\n",
      "Epoch 19/20\n",
      "134/134 [==============================] - 32s 236ms/step - loss: 1.8586 - accuracy: 0.2922 - val_loss: 1.7151 - val_accuracy: 0.3302\n",
      "Epoch 20/20\n",
      "134/134 [==============================] - 35s 260ms/step - loss: 1.7849 - accuracy: 0.3082 - val_loss: 1.7517 - val_accuracy: 0.3246\n",
      "17/17 [==============================] - 3s 171ms/step - loss: 1.7517 - accuracy: 0.3246\n",
      "Validation Loss: 1.751709222793579\n",
      "Validation Accuracy: 0.32457786798477173\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 100, 100)         400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Training with batch size: 32\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 36s 379ms/step - loss: 3.4199 - accuracy: 0.1182 - val_loss: 2.2783 - val_accuracy: 0.1520\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 3.0256 - accuracy: 0.1201 - val_loss: 2.2715 - val_accuracy: 0.1595\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 26s 380ms/step - loss: 2.8556 - accuracy: 0.1191 - val_loss: 2.2310 - val_accuracy: 0.1857\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 26s 381ms/step - loss: 2.6835 - accuracy: 0.1421 - val_loss: 2.2450 - val_accuracy: 0.1651\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 25s 365ms/step - loss: 2.5905 - accuracy: 0.1463 - val_loss: 2.2206 - val_accuracy: 0.1839\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 2.4580 - accuracy: 0.1614 - val_loss: 2.2129 - val_accuracy: 0.1820\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 2.3572 - accuracy: 0.1829 - val_loss: 2.1158 - val_accuracy: 0.2139\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 2.2857 - accuracy: 0.1975 - val_loss: 2.1450 - val_accuracy: 0.2045\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 25s 364ms/step - loss: 2.2292 - accuracy: 0.1956 - val_loss: 2.0947 - val_accuracy: 0.2064\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 2.1658 - accuracy: 0.1984 - val_loss: 1.9814 - val_accuracy: 0.2383\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 2.1142 - accuracy: 0.2101 - val_loss: 2.0790 - val_accuracy: 0.2589\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 2.0339 - accuracy: 0.2392 - val_loss: 1.9499 - val_accuracy: 0.2983\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 1.9927 - accuracy: 0.2458 - val_loss: 1.8914 - val_accuracy: 0.3002\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 1.9273 - accuracy: 0.2631 - val_loss: 1.9369 - val_accuracy: 0.2814\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 1.9141 - accuracy: 0.2800 - val_loss: 1.8489 - val_accuracy: 0.2908\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 1.8692 - accuracy: 0.2885 - val_loss: 1.8181 - val_accuracy: 0.3058\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 1.7878 - accuracy: 0.3100 - val_loss: 1.8455 - val_accuracy: 0.3077\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 1.8851 - accuracy: 0.2838 - val_loss: 1.8459 - val_accuracy: 0.3039\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 26s 378ms/step - loss: 1.7760 - accuracy: 0.3222 - val_loss: 1.7444 - val_accuracy: 0.3340\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 25s 371ms/step - loss: 1.7354 - accuracy: 0.3354 - val_loss: 1.7542 - val_accuracy: 0.3396\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.7542 - accuracy: 0.3396\n",
      "Validation Loss: 1.7541600465774536\n",
      "Validation Accuracy: 0.3395872414112091\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Training with batch size: 64\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 36s 760ms/step - loss: 3.5147 - accuracy: 0.1065 - val_loss: 2.3053 - val_accuracy: 0.1201\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 81s 2s/step - loss: 3.1771 - accuracy: 0.1173 - val_loss: 2.3052 - val_accuracy: 0.1163\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 87s 3s/step - loss: 2.9638 - accuracy: 0.1191 - val_loss: 2.2925 - val_accuracy: 0.1332\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 73s 2s/step - loss: 2.8804 - accuracy: 0.1271 - val_loss: 2.2844 - val_accuracy: 0.1182\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 80s 2s/step - loss: 2.7213 - accuracy: 0.1351 - val_loss: 2.2841 - val_accuracy: 0.1388\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 63s 2s/step - loss: 2.6996 - accuracy: 0.1360 - val_loss: 2.2719 - val_accuracy: 0.1220\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 73s 2s/step - loss: 2.6164 - accuracy: 0.1243 - val_loss: 2.2418 - val_accuracy: 0.1313\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 74s 2s/step - loss: 2.5616 - accuracy: 0.1426 - val_loss: 2.2345 - val_accuracy: 0.1576\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 56s 2s/step - loss: 2.5101 - accuracy: 0.1529 - val_loss: 2.2187 - val_accuracy: 0.1557\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 61s 2s/step - loss: 2.4088 - accuracy: 0.1604 - val_loss: 2.2277 - val_accuracy: 0.1520\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 2.3509 - accuracy: 0.1787 - val_loss: 2.2001 - val_accuracy: 0.1932\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 2.3183 - accuracy: 0.1787 - val_loss: 2.1739 - val_accuracy: 0.1914\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 2.2644 - accuracy: 0.1811 - val_loss: 2.1453 - val_accuracy: 0.1914\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 2.2418 - accuracy: 0.2078 - val_loss: 2.1820 - val_accuracy: 0.1820\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 2.1737 - accuracy: 0.2068 - val_loss: 2.1215 - val_accuracy: 0.2139\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 2.1233 - accuracy: 0.2106 - val_loss: 2.2056 - val_accuracy: 0.1895\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 2.1229 - accuracy: 0.2195 - val_loss: 2.1306 - val_accuracy: 0.2045\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 2.0812 - accuracy: 0.2275 - val_loss: 2.1084 - val_accuracy: 0.2214\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 2.0016 - accuracy: 0.2486 - val_loss: 2.0801 - val_accuracy: 0.2420\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 1.9902 - accuracy: 0.2542 - val_loss: 2.0978 - val_accuracy: 0.2458\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 2.0978 - accuracy: 0.2458\n",
      "Validation Loss: 2.0977864265441895\n",
      "Validation Accuracy: 0.24577860534191132\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Training with batch size: 128\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 46s 2s/step - loss: 3.5255 - accuracy: 0.1140 - val_loss: 2.3047 - val_accuracy: 0.1257\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 3.1927 - accuracy: 0.1196 - val_loss: 2.2943 - val_accuracy: 0.1182\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 3.0520 - accuracy: 0.1224 - val_loss: 2.2922 - val_accuracy: 0.1182\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.9574 - accuracy: 0.1295 - val_loss: 2.2869 - val_accuracy: 0.1163\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.8380 - accuracy: 0.1234 - val_loss: 2.2670 - val_accuracy: 0.1276\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 2.7441 - accuracy: 0.1313 - val_loss: 2.2519 - val_accuracy: 0.1538\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 39s 2s/step - loss: 2.6626 - accuracy: 0.1393 - val_loss: 2.2408 - val_accuracy: 0.1538\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 41s 2s/step - loss: 2.6036 - accuracy: 0.1445 - val_loss: 2.2211 - val_accuracy: 0.1745\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 42s 2s/step - loss: 2.5594 - accuracy: 0.1642 - val_loss: 2.1895 - val_accuracy: 0.1914\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 39s 2s/step - loss: 2.5018 - accuracy: 0.1665 - val_loss: 2.1744 - val_accuracy: 0.1707\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 2.4062 - accuracy: 0.1876 - val_loss: 2.1529 - val_accuracy: 0.1989\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.3816 - accuracy: 0.1811 - val_loss: 2.1270 - val_accuracy: 0.2176\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.2977 - accuracy: 0.1890 - val_loss: 2.1289 - val_accuracy: 0.1970\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 2.2899 - accuracy: 0.2008 - val_loss: 2.0846 - val_accuracy: 0.2120\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 2.2157 - accuracy: 0.2139 - val_loss: 2.0765 - val_accuracy: 0.2214\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.1727 - accuracy: 0.2331 - val_loss: 2.0661 - val_accuracy: 0.2289\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 36s 2s/step - loss: 2.1078 - accuracy: 0.2341 - val_loss: 2.0377 - val_accuracy: 0.2552\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.0795 - accuracy: 0.2420 - val_loss: 2.0043 - val_accuracy: 0.2627\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 2.0125 - accuracy: 0.2692 - val_loss: 2.0344 - val_accuracy: 0.2552\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 37s 2s/step - loss: 1.9658 - accuracy: 0.2706 - val_loss: 1.9975 - val_accuracy: 0.2514\n",
      "17/17 [==============================] - 3s 184ms/step - loss: 1.9975 - accuracy: 0.2514\n",
      "Validation Loss: 1.9975076913833618\n",
      "Validation Accuracy: 0.25140711665153503\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f'Training with batch size: {batch_size}')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=batch_size)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Validation Loss: {loss}')\n",
    "    print(f'Validation Accuracy: {accuracy}')\n",
    "    \n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(100, return_sequences=True)(input_layer) #512, 256, 128, 100\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(100)(x) #128\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(200, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed91b70-dd30-4f8f-8224-17e620faa457",
   "metadata": {},
   "source": [
    "### Conclusion :bacth size 32 win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cda87-14f9-4b66-94b8-7af2f763356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model with more layer\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555602ca-c1f6-40f6-b483-ecf3bc9b9997",
   "metadata": {},
   "source": [
    "## test sur les dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc219646-d086-4360-a595-b8a39dc16d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 64s 833ms/step - loss: 2.7263 - accuracy: 0.1229 - val_loss: 2.2870 - val_accuracy: 0.1051\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 51s 760ms/step - loss: 2.3247 - accuracy: 0.1787 - val_loss: 2.2598 - val_accuracy: 0.1144\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 53s 791ms/step - loss: 2.2391 - accuracy: 0.1947 - val_loss: 2.2294 - val_accuracy: 0.1651\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 50s 740ms/step - loss: 2.0902 - accuracy: 0.2462 - val_loss: 2.1969 - val_accuracy: 0.2064\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 51s 757ms/step - loss: 1.9795 - accuracy: 0.2932 - val_loss: 2.0878 - val_accuracy: 0.2158\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 50s 740ms/step - loss: 1.8489 - accuracy: 0.3307 - val_loss: 2.0815 - val_accuracy: 0.2383\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 49s 743ms/step - loss: 1.7236 - accuracy: 0.3762 - val_loss: 2.0026 - val_accuracy: 0.2814\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 51s 762ms/step - loss: 1.6399 - accuracy: 0.3926 - val_loss: 2.1749 - val_accuracy: 0.2345\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 49s 728ms/step - loss: 1.5645 - accuracy: 0.4301 - val_loss: 2.1383 - val_accuracy: 0.2739\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 49s 739ms/step - loss: 1.4613 - accuracy: 0.4681 - val_loss: 1.9881 - val_accuracy: 0.3208\n",
      "17/17 [==============================] - 3s 188ms/step - loss: 1.9881 - accuracy: 0.3208\n",
      "dropout : 0.1 Test accuracy: 0.3208255171775818\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 76s 933ms/step - loss: 2.8540 - accuracy: 0.1018 - val_loss: 2.3034 - val_accuracy: 0.0976\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 62s 928ms/step - loss: 2.5489 - accuracy: 0.1431 - val_loss: 2.3004 - val_accuracy: 0.1313\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 61s 906ms/step - loss: 2.4853 - accuracy: 0.1370 - val_loss: 2.3006 - val_accuracy: 0.1351\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 60s 892ms/step - loss: 2.3426 - accuracy: 0.1698 - val_loss: 2.3262 - val_accuracy: 0.1463\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 60s 900ms/step - loss: 2.3002 - accuracy: 0.1857 - val_loss: 2.3137 - val_accuracy: 0.1445\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 62s 919ms/step - loss: 2.2392 - accuracy: 0.2022 - val_loss: 2.2825 - val_accuracy: 0.1407\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 63s 937ms/step - loss: 2.1845 - accuracy: 0.2087 - val_loss: 2.2771 - val_accuracy: 0.1370\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 61s 910ms/step - loss: 2.1182 - accuracy: 0.2402 - val_loss: 2.2751 - val_accuracy: 0.1876\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 63s 947ms/step - loss: 2.0218 - accuracy: 0.2556 - val_loss: 2.1631 - val_accuracy: 0.2289\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 62s 922ms/step - loss: 1.9524 - accuracy: 0.2842 - val_loss: 2.2165 - val_accuracy: 0.2195\n",
      "17/17 [==============================] - 4s 254ms/step - loss: 2.2165 - accuracy: 0.2195\n",
      "dropout : 0.2 Test accuracy: 0.2195121943950653\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 69s 907ms/step - loss: 2.9894 - accuracy: 0.1126 - val_loss: 2.3043 - val_accuracy: 0.0957\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 58s 870ms/step - loss: 2.5940 - accuracy: 0.1548 - val_loss: 2.2962 - val_accuracy: 0.1351\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 60s 890ms/step - loss: 2.4459 - accuracy: 0.1735 - val_loss: 2.2957 - val_accuracy: 0.1051\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 61s 916ms/step - loss: 2.3865 - accuracy: 0.1745 - val_loss: 2.2387 - val_accuracy: 0.1407\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 60s 897ms/step - loss: 2.2694 - accuracy: 0.2106 - val_loss: 2.1762 - val_accuracy: 0.1932\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 61s 911ms/step - loss: 2.2007 - accuracy: 0.2176 - val_loss: 2.1888 - val_accuracy: 0.2045\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 57s 852ms/step - loss: 2.1261 - accuracy: 0.2350 - val_loss: 2.1723 - val_accuracy: 0.2251\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 58s 868ms/step - loss: 2.0524 - accuracy: 0.2631 - val_loss: 2.0366 - val_accuracy: 0.2383\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 58s 871ms/step - loss: 1.9700 - accuracy: 0.2683 - val_loss: 2.1059 - val_accuracy: 0.2158\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 57s 857ms/step - loss: 1.9485 - accuracy: 0.2758 - val_loss: 2.0143 - val_accuracy: 0.2420\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 2.0143 - accuracy: 0.2420\n",
      "dropout : 0.3 Test accuracy: 0.24202626943588257\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 68s 896ms/step - loss: 3.1538 - accuracy: 0.1238 - val_loss: 2.3186 - val_accuracy: 0.0807\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 62s 927ms/step - loss: 2.8957 - accuracy: 0.1130 - val_loss: 2.2958 - val_accuracy: 0.1238\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 62s 931ms/step - loss: 2.7147 - accuracy: 0.1238 - val_loss: 2.2976 - val_accuracy: 0.1501\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 61s 908ms/step - loss: 2.5969 - accuracy: 0.1463 - val_loss: 2.2944 - val_accuracy: 0.1689\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 62s 932ms/step - loss: 2.4851 - accuracy: 0.1557 - val_loss: 2.2704 - val_accuracy: 0.1482\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 62s 928ms/step - loss: 2.4252 - accuracy: 0.1595 - val_loss: 2.3166 - val_accuracy: 0.1388\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 63s 939ms/step - loss: 2.3959 - accuracy: 0.1614 - val_loss: 2.2774 - val_accuracy: 0.1782\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 61s 911ms/step - loss: 2.3113 - accuracy: 0.1895 - val_loss: 2.2266 - val_accuracy: 0.1689\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 62s 927ms/step - loss: 2.2309 - accuracy: 0.2068 - val_loss: 2.1732 - val_accuracy: 0.2195\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 60s 895ms/step - loss: 2.1801 - accuracy: 0.2144 - val_loss: 2.1097 - val_accuracy: 0.2233\n",
      "17/17 [==============================] - 3s 202ms/step - loss: 2.1097 - accuracy: 0.2233\n",
      "dropout : 0.4 Test accuracy: 0.22326454520225525\n"
     ]
    }
   ],
   "source": [
    "dropouts=[0.1, 0.2, 0.3, 0.4,0.5]\n",
    "for dropout in dropouts:\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(100, return_sequences=True)(input_layer) #512, 256, 128, 100\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(100)(x) #128\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(200, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #f1 score, \n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "    ## modifier le batch size >32\n",
    "    \n",
    "    # Evaluate the model with more layer\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f'dropout : {dropout} Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34aa35-bc1d-4ab9-9767-1c5502bb3929",
   "metadata": {},
   "source": [
    "### conclusion dropout 0.1 best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694905ff-5b16-41f3-b7f2-c315af361bc7",
   "metadata": {},
   "source": [
    "### test des nombre de neurones dans les couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faa7858b-f4fb-461e-9f8e-215c16a36767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with LSTM units: 50 and Dense units: 100\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 100, 50)           18600     \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 100, 50)          200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 100, 50)           0         \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 50)               200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,710\n",
      "Trainable params: 45,310\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "Validation Loss: 2.2193989753723145, Validation Accuracy: 0.18198874592781067\n",
      "Testing model with LSTM units: 50 and Dense units: 200\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 100, 50)           18600     \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 100, 50)          200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 100, 50)           0         \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 50)               200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 200)               10200     \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,210\n",
      "Trainable params: 51,610\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Validation Loss: 2.1872005462646484, Validation Accuracy: 0.19136960804462433\n",
      "Testing model with LSTM units: 50 and Dense units: 300\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 100, 50)           18600     \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 100, 50)          200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 100, 50)           0         \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 50)               200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 300)               15300     \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,710\n",
      "Trainable params: 57,910\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Validation Loss: 2.2757041454315186, Validation Accuracy: 0.17636021971702576\n",
      "Testing model with LSTM units: 100 and Dense units: 100\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,910\n",
      "Trainable params: 149,310\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Validation Loss: 2.0554821491241455, Validation Accuracy: 0.24953095614910126\n",
      "Testing model with LSTM units: 100 and Dense units: 200\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,410\n",
      "Trainable params: 160,610\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Validation Loss: 1.9396659135818481, Validation Accuracy: 0.3133208155632019\n",
      "Testing model with LSTM units: 100 and Dense units: 300\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 100, 100)         400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 300)               30300     \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,910\n",
      "Trainable params: 171,910\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "Validation Loss: 2.10736083984375, Validation Accuracy: 0.21763601899147034\n",
      "Testing model with LSTM units: 150 and Dense units: 100\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 100, 150)          115800    \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 100, 150)         600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 150)               180600    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314,110\n",
      "Trainable params: 313,310\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Validation Loss: 1.8472745418548584, Validation Accuracy: 0.32457786798477173\n",
      "Testing model with LSTM units: 150 and Dense units: 200\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 100, 150)          115800    \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 100, 150)         600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 150)               180600    \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 200)               30200     \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330,610\n",
      "Trainable params: 329,610\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "Validation Loss: 2.0277321338653564, Validation Accuracy: 0.24202626943588257\n",
      "Testing model with LSTM units: 150 and Dense units: 300\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 100, 150)          115800    \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 100, 150)         600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, 150)               180600    \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 300)               45300     \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 347,110\n",
      "Trainable params: 345,910\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "Validation Loss: 1.9319099187850952, Validation Accuracy: 0.3058161437511444\n"
     ]
    }
   ],
   "source": [
    "def create_model(lstm_num,dense_num):\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(lstm_num, return_sequences=True)(input_layer) #512, 256, 128, 100\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(lstm_num)(x) #128\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(dense_num, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "lstm_units_list = [50, 100, 150]\n",
    "dense_units_list = [100, 200, 300]\n",
    "\n",
    "# Dictionnaire pour enregistrer les résultats\n",
    "results = {}\n",
    "for lstm_units in lstm_units_list:\n",
    "    for dense_units in dense_units_list:\n",
    "        print(f'Testing model with LSTM units: {lstm_units} and Dense units: {dense_units}')\n",
    "        model = create_model(lstm_units, dense_units)\n",
    "        model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=0)\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}')\n",
    "        results[(lstm_units, dense_units)] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298ade86-fc59-4bcd-9062-6248fd5e5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM units: 50, Dense units: 100 -> Validation Accuracy: 0.18198874592781067\n",
      "LSTM units: 50, Dense units: 200 -> Validation Accuracy: 0.19136960804462433\n",
      "LSTM units: 50, Dense units: 300 -> Validation Accuracy: 0.17636021971702576\n",
      "LSTM units: 100, Dense units: 100 -> Validation Accuracy: 0.24953095614910126\n",
      "LSTM units: 100, Dense units: 200 -> Validation Accuracy: 0.3133208155632019\n",
      "LSTM units: 100, Dense units: 300 -> Validation Accuracy: 0.21763601899147034\n",
      "LSTM units: 150, Dense units: 100 -> Validation Accuracy: 0.32457786798477173\n",
      "LSTM units: 150, Dense units: 200 -> Validation Accuracy: 0.24202626943588257\n",
      "LSTM units: 150, Dense units: 300 -> Validation Accuracy: 0.3058161437511444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Afficher les résultats\n",
    "for config, accuracy in results.items():\n",
    "    print(f'LSTM units: {config[0]}, Dense units: {config[1]} -> Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb0528-5658-4346-836c-d957cd186be9",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "LSTM units: 150, Dense units: 100 -> Validation Accuracy: 0.32457786798477173\n",
    "LSTM units: 100, Dense units: 200 -> Validation Accuracy: 0.3133208155632019\n",
    "LSTM units: 150, Dense units: 300 -> Validation Accuracy: 0.3058161437511444\n",
    "voila les 2 meilleurs resulats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a43a11-0bb7-44f5-b47d-0d5c2d784fb2",
   "metadata": {},
   "source": [
    "#### augmentons l'epoche pour voir le resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a41c77-e2f2-4313-bc06-b1e7bc6bfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with LSTM units: 100 and Dense units: 200\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100, 100)          57200     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159,810\n",
      "Trainable params: 159,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "67/67 [==============================] - 44s 551ms/step - loss: 2.3078 - accuracy: 0.1191 - val_loss: 2.2946 - val_accuracy: 0.1126\n",
      "Epoch 2/70\n",
      "67/67 [==============================] - 37s 559ms/step - loss: 2.2734 - accuracy: 0.1398 - val_loss: 2.2638 - val_accuracy: 0.1689\n",
      "Epoch 3/70\n",
      "67/67 [==============================] - 39s 590ms/step - loss: 2.2024 - accuracy: 0.1806 - val_loss: 2.1534 - val_accuracy: 0.1857\n",
      "Epoch 4/70\n",
      "67/67 [==============================] - 41s 610ms/step - loss: 2.0656 - accuracy: 0.2190 - val_loss: 2.0271 - val_accuracy: 0.2420\n",
      "Epoch 5/70\n",
      "67/67 [==============================] - 38s 571ms/step - loss: 1.9745 - accuracy: 0.2598 - val_loss: 2.1469 - val_accuracy: 0.1970\n",
      "Epoch 6/70\n",
      "67/67 [==============================] - 42s 626ms/step - loss: 1.9441 - accuracy: 0.2594 - val_loss: 1.9477 - val_accuracy: 0.2289\n",
      "Epoch 7/70\n",
      "67/67 [==============================] - 35s 515ms/step - loss: 1.8453 - accuracy: 0.3086 - val_loss: 1.8053 - val_accuracy: 0.3171\n",
      "Epoch 8/70\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 1.7343 - accuracy: 0.3462 - val_loss: 1.7922 - val_accuracy: 0.3133\n",
      "Epoch 9/70\n",
      "67/67 [==============================] - 38s 572ms/step - loss: 1.6283 - accuracy: 0.3846 - val_loss: 1.9050 - val_accuracy: 0.3021\n",
      "Epoch 10/70\n",
      "67/67 [==============================] - 38s 574ms/step - loss: 1.5953 - accuracy: 0.4067 - val_loss: 1.8468 - val_accuracy: 0.3227\n",
      "Epoch 11/70\n",
      "67/67 [==============================] - 39s 588ms/step - loss: 1.5659 - accuracy: 0.4231 - val_loss: 1.8961 - val_accuracy: 0.2946\n",
      "Epoch 12/70\n",
      "67/67 [==============================] - 38s 568ms/step - loss: 1.5574 - accuracy: 0.4095 - val_loss: 1.7283 - val_accuracy: 0.3377\n",
      "Epoch 13/70\n",
      "67/67 [==============================] - 39s 582ms/step - loss: 1.4019 - accuracy: 0.4831 - val_loss: 1.6039 - val_accuracy: 0.4109\n",
      "Epoch 14/70\n",
      "67/67 [==============================] - 42s 631ms/step - loss: 1.2749 - accuracy: 0.5150 - val_loss: 1.5087 - val_accuracy: 0.4522\n",
      "Epoch 15/70\n",
      "67/67 [==============================] - 42s 620ms/step - loss: 1.1701 - accuracy: 0.5629 - val_loss: 1.5910 - val_accuracy: 0.4259\n",
      "Epoch 16/70\n",
      "67/67 [==============================] - 42s 635ms/step - loss: 1.0738 - accuracy: 0.5985 - val_loss: 1.6759 - val_accuracy: 0.4278\n",
      "Epoch 17/70\n",
      "67/67 [==============================] - 44s 661ms/step - loss: 1.0356 - accuracy: 0.6144 - val_loss: 1.4637 - val_accuracy: 0.4972\n",
      "Epoch 18/70\n",
      "67/67 [==============================] - 42s 632ms/step - loss: 0.9492 - accuracy: 0.6449 - val_loss: 1.4027 - val_accuracy: 0.5103\n",
      "Epoch 19/70\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 0.8607 - accuracy: 0.6871 - val_loss: 1.3326 - val_accuracy: 0.5141\n",
      "Epoch 20/70\n",
      "67/67 [==============================] - 39s 586ms/step - loss: 0.7730 - accuracy: 0.7162 - val_loss: 1.3102 - val_accuracy: 0.5366\n",
      "Epoch 21/70\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 0.7094 - accuracy: 0.7420 - val_loss: 1.3235 - val_accuracy: 0.5310\n",
      "Epoch 22/70\n",
      "67/67 [==============================] - 41s 610ms/step - loss: 0.6991 - accuracy: 0.7416 - val_loss: 1.3689 - val_accuracy: 0.5516\n",
      "Epoch 23/70\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.6689 - accuracy: 0.7542 - val_loss: 1.3542 - val_accuracy: 0.5403\n",
      "Epoch 24/70\n",
      "67/67 [==============================] - 41s 618ms/step - loss: 0.5696 - accuracy: 0.7908 - val_loss: 1.3359 - val_accuracy: 0.5760\n",
      "Epoch 25/70\n",
      "67/67 [==============================] - 42s 629ms/step - loss: 0.4988 - accuracy: 0.8199 - val_loss: 1.3021 - val_accuracy: 0.6079\n",
      "Epoch 26/70\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.4607 - accuracy: 0.8293 - val_loss: 1.3185 - val_accuracy: 0.5797\n",
      "Epoch 27/70\n",
      "67/67 [==============================] - 41s 620ms/step - loss: 0.4812 - accuracy: 0.8246 - val_loss: 1.3338 - val_accuracy: 0.6004\n",
      "Epoch 28/70\n",
      "67/67 [==============================] - 39s 589ms/step - loss: 0.4754 - accuracy: 0.8222 - val_loss: 1.3410 - val_accuracy: 0.6173\n",
      "Epoch 29/70\n",
      "67/67 [==============================] - 44s 657ms/step - loss: 0.4461 - accuracy: 0.8330 - val_loss: 1.4182 - val_accuracy: 0.5929\n",
      "Epoch 30/70\n",
      "67/67 [==============================] - 44s 664ms/step - loss: 0.3757 - accuracy: 0.8621 - val_loss: 1.3100 - val_accuracy: 0.6417\n",
      "Epoch 31/70\n",
      "67/67 [==============================] - 45s 667ms/step - loss: 0.3633 - accuracy: 0.8607 - val_loss: 1.3637 - val_accuracy: 0.6079\n",
      "Epoch 32/70\n",
      "67/67 [==============================] - 45s 674ms/step - loss: 0.3204 - accuracy: 0.8818 - val_loss: 1.4610 - val_accuracy: 0.5854\n",
      "Epoch 33/70\n",
      "67/67 [==============================] - 48s 712ms/step - loss: 0.3320 - accuracy: 0.8785 - val_loss: 1.4199 - val_accuracy: 0.6079\n",
      "Epoch 34/70\n",
      "67/67 [==============================] - 46s 683ms/step - loss: 0.3163 - accuracy: 0.8917 - val_loss: 1.5298 - val_accuracy: 0.6098\n",
      "Epoch 35/70\n",
      "67/67 [==============================] - 45s 671ms/step - loss: 0.3107 - accuracy: 0.8874 - val_loss: 1.5646 - val_accuracy: 0.5947\n",
      "Epoch 36/70\n",
      "67/67 [==============================] - 42s 629ms/step - loss: 0.2545 - accuracy: 0.9137 - val_loss: 1.4749 - val_accuracy: 0.6341\n",
      "Epoch 37/70\n",
      "67/67 [==============================] - 44s 658ms/step - loss: 0.3572 - accuracy: 0.8841 - val_loss: 1.3565 - val_accuracy: 0.6567\n",
      "Epoch 38/70\n",
      "67/67 [==============================] - 41s 604ms/step - loss: 0.2368 - accuracy: 0.9212 - val_loss: 1.4237 - val_accuracy: 0.6266\n",
      "Epoch 39/70\n",
      "67/67 [==============================] - 47s 705ms/step - loss: 0.2046 - accuracy: 0.9273 - val_loss: 1.4376 - val_accuracy: 0.6510\n",
      "Epoch 40/70\n",
      "67/67 [==============================] - 45s 667ms/step - loss: 0.1848 - accuracy: 0.9311 - val_loss: 1.5435 - val_accuracy: 0.6079\n",
      "Epoch 41/70\n",
      "67/67 [==============================] - 43s 635ms/step - loss: 0.2130 - accuracy: 0.9193 - val_loss: 1.5035 - val_accuracy: 0.6304\n",
      "Epoch 42/70\n",
      "67/67 [==============================] - 45s 672ms/step - loss: 0.1659 - accuracy: 0.9470 - val_loss: 1.7461 - val_accuracy: 0.6191\n",
      "Epoch 43/70\n",
      "67/67 [==============================] - 45s 675ms/step - loss: 0.2313 - accuracy: 0.9217 - val_loss: 1.5876 - val_accuracy: 0.6379\n",
      "Epoch 44/70\n",
      "67/67 [==============================] - 45s 668ms/step - loss: 0.2943 - accuracy: 0.9099 - val_loss: 1.4159 - val_accuracy: 0.6304\n",
      "Epoch 45/70\n",
      "67/67 [==============================] - 46s 686ms/step - loss: 0.2095 - accuracy: 0.9287 - val_loss: 1.4663 - val_accuracy: 0.6323\n",
      "Epoch 46/70\n",
      "67/67 [==============================] - 45s 673ms/step - loss: 0.1937 - accuracy: 0.9329 - val_loss: 1.5095 - val_accuracy: 0.6379\n",
      "Epoch 47/70\n",
      "67/67 [==============================] - 50s 748ms/step - loss: 0.1445 - accuracy: 0.9484 - val_loss: 1.5348 - val_accuracy: 0.6548\n",
      "Epoch 48/70\n",
      "67/67 [==============================] - 50s 742ms/step - loss: 0.1110 - accuracy: 0.9634 - val_loss: 1.5891 - val_accuracy: 0.6679\n",
      "Epoch 49/70\n",
      "67/67 [==============================] - 49s 729ms/step - loss: 0.0979 - accuracy: 0.9662 - val_loss: 1.6187 - val_accuracy: 0.6379\n",
      "Epoch 50/70\n",
      "67/67 [==============================] - 47s 696ms/step - loss: 0.2048 - accuracy: 0.9306 - val_loss: 1.5951 - val_accuracy: 0.6398\n",
      "Epoch 51/70\n",
      "67/67 [==============================] - 47s 699ms/step - loss: 0.1392 - accuracy: 0.9540 - val_loss: 1.6376 - val_accuracy: 0.6341\n",
      "Epoch 52/70\n",
      "67/67 [==============================] - 50s 743ms/step - loss: 0.1568 - accuracy: 0.9512 - val_loss: 1.5895 - val_accuracy: 0.6417\n",
      "Epoch 53/70\n",
      "67/67 [==============================] - 47s 711ms/step - loss: 0.1567 - accuracy: 0.9428 - val_loss: 1.6520 - val_accuracy: 0.6435\n",
      "Epoch 54/70\n",
      "67/67 [==============================] - 45s 665ms/step - loss: 0.1866 - accuracy: 0.9357 - val_loss: 1.6332 - val_accuracy: 0.6529\n",
      "Epoch 55/70\n",
      "67/67 [==============================] - 42s 633ms/step - loss: 0.1250 - accuracy: 0.9578 - val_loss: 1.6394 - val_accuracy: 0.6642\n",
      "Epoch 56/70\n",
      "67/67 [==============================] - 44s 654ms/step - loss: 0.1569 - accuracy: 0.9442 - val_loss: 1.5834 - val_accuracy: 0.6660\n",
      "Epoch 57/70\n",
      "67/67 [==============================] - 43s 640ms/step - loss: 0.1005 - accuracy: 0.9634 - val_loss: 1.5338 - val_accuracy: 0.6642\n",
      "Epoch 58/70\n",
      "67/67 [==============================] - 45s 673ms/step - loss: 0.0896 - accuracy: 0.9742 - val_loss: 1.5299 - val_accuracy: 0.6848\n",
      "Epoch 59/70\n",
      "67/67 [==============================] - 43s 650ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 1.6456 - val_accuracy: 0.6717\n",
      "Epoch 60/70\n",
      "67/67 [==============================] - 42s 634ms/step - loss: 0.0779 - accuracy: 0.9747 - val_loss: 1.8119 - val_accuracy: 0.6660\n",
      "Epoch 61/70\n",
      "67/67 [==============================] - 44s 656ms/step - loss: 0.1074 - accuracy: 0.9644 - val_loss: 1.8738 - val_accuracy: 0.6304\n",
      "Epoch 62/70\n",
      "67/67 [==============================] - 44s 655ms/step - loss: 0.0839 - accuracy: 0.9751 - val_loss: 1.7076 - val_accuracy: 0.6435\n",
      "Epoch 63/70\n",
      "67/67 [==============================] - 43s 643ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 1.6997 - val_accuracy: 0.6848\n",
      "Epoch 64/70\n",
      "67/67 [==============================] - 44s 658ms/step - loss: 0.0396 - accuracy: 0.9906 - val_loss: 1.6392 - val_accuracy: 0.6829\n",
      "Epoch 65/70\n",
      "67/67 [==============================] - 44s 653ms/step - loss: 0.0279 - accuracy: 0.9934 - val_loss: 1.7310 - val_accuracy: 0.6773\n",
      "Epoch 66/70\n",
      "67/67 [==============================] - 44s 665ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 1.7582 - val_accuracy: 0.7036\n",
      "Epoch 67/70\n",
      "67/67 [==============================] - 44s 659ms/step - loss: 0.0171 - accuracy: 0.9930 - val_loss: 1.8874 - val_accuracy: 0.6942\n",
      "Epoch 68/70\n",
      "67/67 [==============================] - 42s 634ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 1.8347 - val_accuracy: 0.6979\n",
      "Epoch 69/70\n",
      "67/67 [==============================] - 43s 637ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 1.9274 - val_accuracy: 0.6792\n",
      "Epoch 70/70\n",
      "67/67 [==============================] - 44s 661ms/step - loss: 0.0610 - accuracy: 0.9817 - val_loss: 1.9666 - val_accuracy: 0.6660\n",
      "Validation Loss: 1.9666402339935303, Validation Accuracy: 0.6660412549972534\n"
     ]
    }
   ],
   "source": [
    "def create_model(lstm_num,dense_num):\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(lstm_num, return_sequences=True)(input_layer) #512, 256, 128, 100 \n",
    "    x = Dropout(0.1)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(lstm_num)(x) # \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(dense_num, activation='relu')(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    " \n",
    "print(f'Testing model with LSTM units: {100} and Dense units: {200}')\n",
    "model = create_model(100, 200)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=32, verbose=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1314d2-7cda-42b3-a734-b82928c9f2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6c837b-46ee-45c1-87a0-faac7980faf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with LSTM units: 150 and Dense units: 100\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100, 150)          115800    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 150)               180600    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 312,510\n",
      "Trainable params: 312,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "67/67 [==============================] - 130s 2s/step - loss: 2.3160 - accuracy: 0.1102 - val_loss: 2.2959 - val_accuracy: 0.1595\n",
      "Epoch 2/70\n",
      "67/67 [==============================] - 128s 2s/step - loss: 2.1849 - accuracy: 0.1717 - val_loss: 2.1361 - val_accuracy: 0.1914\n",
      "Epoch 3/70\n",
      "67/67 [==============================] - 120s 2s/step - loss: 2.1044 - accuracy: 0.2064 - val_loss: 2.1914 - val_accuracy: 0.1595\n",
      "Epoch 4/70\n",
      "67/67 [==============================] - 129s 2s/step - loss: 2.0298 - accuracy: 0.2284 - val_loss: 1.9861 - val_accuracy: 0.2420\n",
      "Epoch 5/70\n",
      "67/67 [==============================] - 127s 2s/step - loss: 1.9258 - accuracy: 0.2725 - val_loss: 1.9355 - val_accuracy: 0.2720\n",
      "Epoch 6/70\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.8505 - accuracy: 0.3002 - val_loss: 1.9190 - val_accuracy: 0.2589\n",
      "Epoch 7/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 1.7481 - accuracy: 0.3227 - val_loss: 1.9005 - val_accuracy: 0.2533\n",
      "Epoch 8/70\n",
      "67/67 [==============================] - 110s 2s/step - loss: 1.7897 - accuracy: 0.3363 - val_loss: 1.8332 - val_accuracy: 0.3189\n",
      "Epoch 9/70\n",
      "67/67 [==============================] - 122s 2s/step - loss: 1.6025 - accuracy: 0.3996 - val_loss: 1.7698 - val_accuracy: 0.3096\n",
      "Epoch 10/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 1.6132 - accuracy: 0.3912 - val_loss: 1.7227 - val_accuracy: 0.3452\n",
      "Epoch 11/70\n",
      "67/67 [==============================] - 124s 2s/step - loss: 1.5034 - accuracy: 0.4254 - val_loss: 1.6724 - val_accuracy: 0.3827\n",
      "Epoch 12/70\n",
      "67/67 [==============================] - 126s 2s/step - loss: 1.3651 - accuracy: 0.4812 - val_loss: 1.5783 - val_accuracy: 0.4259\n",
      "Epoch 13/70\n",
      "67/67 [==============================] - 130s 2s/step - loss: 1.2551 - accuracy: 0.5371 - val_loss: 1.5625 - val_accuracy: 0.4390\n",
      "Epoch 14/70\n",
      "67/67 [==============================] - 123s 2s/step - loss: 1.1363 - accuracy: 0.5957 - val_loss: 1.5291 - val_accuracy: 0.4653\n",
      "Epoch 15/70\n",
      "67/67 [==============================] - 124s 2s/step - loss: 1.1298 - accuracy: 0.5835 - val_loss: 1.3784 - val_accuracy: 0.4859\n",
      "Epoch 16/70\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.9852 - accuracy: 0.6323 - val_loss: 1.3994 - val_accuracy: 0.5159\n",
      "Epoch 17/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.8533 - accuracy: 0.6726 - val_loss: 1.2115 - val_accuracy: 0.5722\n",
      "Epoch 18/70\n",
      "67/67 [==============================] - 137s 2s/step - loss: 0.7769 - accuracy: 0.6984 - val_loss: 1.2332 - val_accuracy: 0.5779\n",
      "Epoch 19/70\n",
      "67/67 [==============================] - 139s 2s/step - loss: 0.7163 - accuracy: 0.7364 - val_loss: 1.2084 - val_accuracy: 0.5854\n",
      "Epoch 20/70\n",
      "67/67 [==============================] - 137s 2s/step - loss: 0.6180 - accuracy: 0.7819 - val_loss: 1.2462 - val_accuracy: 0.6023\n",
      "Epoch 21/70\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.5324 - accuracy: 0.8096 - val_loss: 1.3364 - val_accuracy: 0.5910\n",
      "Epoch 22/70\n",
      "67/67 [==============================] - 137s 2s/step - loss: 0.6287 - accuracy: 0.7688 - val_loss: 1.2065 - val_accuracy: 0.5985\n",
      "Epoch 23/70\n",
      "67/67 [==============================] - 141s 2s/step - loss: 0.4873 - accuracy: 0.8236 - val_loss: 1.1321 - val_accuracy: 0.6341\n",
      "Epoch 24/70\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.4207 - accuracy: 0.8476 - val_loss: 1.0731 - val_accuracy: 0.6735\n",
      "Epoch 25/70\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.3906 - accuracy: 0.8640 - val_loss: 1.0917 - val_accuracy: 0.6604\n",
      "Epoch 26/70\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.3519 - accuracy: 0.8715 - val_loss: 1.0895 - val_accuracy: 0.6473\n",
      "Epoch 27/70\n",
      "67/67 [==============================] - 143s 2s/step - loss: 0.2944 - accuracy: 0.8949 - val_loss: 1.2186 - val_accuracy: 0.6379\n",
      "Epoch 28/70\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.2815 - accuracy: 0.8963 - val_loss: 1.3028 - val_accuracy: 0.6398\n",
      "Epoch 29/70\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.3566 - accuracy: 0.8799 - val_loss: 1.1182 - val_accuracy: 0.6417\n",
      "Epoch 30/70\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.2323 - accuracy: 0.9179 - val_loss: 1.2295 - val_accuracy: 0.6886\n",
      "Epoch 31/70\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.3624 - accuracy: 0.8720 - val_loss: 1.1522 - val_accuracy: 0.6585\n",
      "Epoch 32/70\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.2668 - accuracy: 0.9085 - val_loss: 0.9923 - val_accuracy: 0.7129\n",
      "Epoch 33/70\n",
      "67/67 [==============================] - 146s 2s/step - loss: 0.1634 - accuracy: 0.9489 - val_loss: 1.0841 - val_accuracy: 0.7092\n",
      "Epoch 34/70\n",
      "67/67 [==============================] - 136s 2s/step - loss: 0.1861 - accuracy: 0.9343 - val_loss: 1.0636 - val_accuracy: 0.7054\n",
      "Epoch 35/70\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.1293 - accuracy: 0.9587 - val_loss: 1.1775 - val_accuracy: 0.6998\n",
      "Epoch 36/70\n",
      "67/67 [==============================] - 130s 2s/step - loss: 0.1269 - accuracy: 0.9592 - val_loss: 1.3273 - val_accuracy: 0.6660\n",
      "Epoch 37/70\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.1319 - accuracy: 0.9545 - val_loss: 1.1192 - val_accuracy: 0.7111\n",
      "Epoch 38/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.0970 - accuracy: 0.9686 - val_loss: 1.1649 - val_accuracy: 0.7411\n",
      "Epoch 39/70\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.0939 - accuracy: 0.9690 - val_loss: 1.3396 - val_accuracy: 0.6979\n",
      "Epoch 40/70\n",
      "67/67 [==============================] - 100s 1s/step - loss: 0.2098 - accuracy: 0.9390 - val_loss: 1.2654 - val_accuracy: 0.6979\n",
      "Epoch 41/70\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.1764 - accuracy: 0.9395 - val_loss: 1.1514 - val_accuracy: 0.7129\n",
      "Epoch 42/70\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.1676 - accuracy: 0.9418 - val_loss: 1.2917 - val_accuracy: 0.6792\n",
      "Epoch 43/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.2445 - accuracy: 0.9170 - val_loss: 1.0676 - val_accuracy: 0.7242\n",
      "Epoch 44/70\n",
      "67/67 [==============================] - 96s 1s/step - loss: 0.1575 - accuracy: 0.9489 - val_loss: 1.0788 - val_accuracy: 0.7392\n",
      "Epoch 45/70\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.1099 - accuracy: 0.9648 - val_loss: 1.2013 - val_accuracy: 0.7205\n",
      "Epoch 46/70\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.0606 - accuracy: 0.9789 - val_loss: 1.2213 - val_accuracy: 0.7111\n",
      "Epoch 47/70\n",
      "67/67 [==============================] - 94s 1s/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 1.3326 - val_accuracy: 0.7280\n",
      "Epoch 48/70\n",
      "67/67 [==============================] - 96s 1s/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 1.2706 - val_accuracy: 0.7186\n",
      "Epoch 49/70\n",
      "67/67 [==============================] - 97s 1s/step - loss: 0.0546 - accuracy: 0.9822 - val_loss: 1.3652 - val_accuracy: 0.7223\n",
      "Epoch 50/70\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.0427 - accuracy: 0.9850 - val_loss: 1.4328 - val_accuracy: 0.7411\n",
      "Epoch 51/70\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.0917 - accuracy: 0.9719 - val_loss: 1.3915 - val_accuracy: 0.7148\n",
      "Epoch 52/70\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.2036 - accuracy: 0.9386 - val_loss: 1.1627 - val_accuracy: 0.7242\n",
      "Epoch 53/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.0994 - accuracy: 0.9658 - val_loss: 1.1791 - val_accuracy: 0.7373\n",
      "Epoch 54/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 1.2775 - val_accuracy: 0.7373\n",
      "Epoch 55/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.1031 - accuracy: 0.9681 - val_loss: 1.5493 - val_accuracy: 0.6923\n",
      "Epoch 56/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.2322 - accuracy: 0.9287 - val_loss: 1.2226 - val_accuracy: 0.7373\n",
      "Epoch 57/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.1926 - accuracy: 0.9395 - val_loss: 1.1731 - val_accuracy: 0.7336\n",
      "Epoch 58/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.0968 - accuracy: 0.9705 - val_loss: 1.0630 - val_accuracy: 0.7411\n",
      "Epoch 59/70\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.0577 - accuracy: 0.9850 - val_loss: 1.0708 - val_accuracy: 0.7505\n",
      "Epoch 60/70\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 1.0808 - val_accuracy: 0.7674\n",
      "Epoch 61/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 1.1768 - val_accuracy: 0.7561\n",
      "Epoch 62/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.0164 - accuracy: 0.9972 - val_loss: 1.1257 - val_accuracy: 0.7824\n",
      "Epoch 63/70\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 1.3104 - val_accuracy: 0.7617\n",
      "Epoch 64/70\n",
      "67/67 [==============================] - 149s 2s/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 1.2981 - val_accuracy: 0.7523\n",
      "Epoch 65/70\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 1.1626 - val_accuracy: 0.7730\n",
      "Epoch 66/70\n",
      "67/67 [==============================] - 154s 2s/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 1.2446 - val_accuracy: 0.7692\n",
      "Epoch 67/70\n",
      "67/67 [==============================] - 163s 2s/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 1.2944 - val_accuracy: 0.7655\n",
      "Epoch 68/70\n",
      "67/67 [==============================] - 161s 2s/step - loss: 0.0872 - accuracy: 0.9756 - val_loss: 1.2575 - val_accuracy: 0.7448\n",
      "Epoch 69/70\n",
      "67/67 [==============================] - 161s 2s/step - loss: 0.1980 - accuracy: 0.9418 - val_loss: 1.1037 - val_accuracy: 0.7636\n",
      "Epoch 70/70\n",
      "67/67 [==============================] - 164s 2s/step - loss: 0.0973 - accuracy: 0.9733 - val_loss: 1.0633 - val_accuracy: 0.7636\n",
      "Validation Loss: 1.0633397102355957, Validation Accuracy: 0.7636022567749023\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mresults\u001b[49m[(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m100\u001b[39m)] \u001b[38;5;241m=\u001b[39m accuracy\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "def create_model(lstm_num,dense_num):\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(lstm_num, return_sequences=True)(input_layer) #512, 256, 128, 100 \n",
    "    x = Dropout(0.1)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(lstm_num)(x) # \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(dense_num, activation='relu')(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    " \n",
    "print(f'Testing model with LSTM units: {150} and Dense units: {100}')\n",
    "model = create_model(150, 100)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=32, verbose=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}')\n",
    "results[(150, 100)] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66a14ac-05cc-4945-be1e-7507c38cf3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 5s 313ms/step - loss: 1.0633 - accuracy: 0.7636\n",
      " Test accuracy: 0.7636022567749023\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f' Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160650f-6c3d-4525-833a-da830c0b3851",
   "metadata": {},
   "source": [
    "plus on augmente le nombre de neurones LSTM plus cela prend du tempd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a83490-6cd8-4742-8e04-6fc6a98729cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c63c8bd-a42e-4171-b73f-e9aaf8aee3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with LSTM units: 150 and Dense units: 300\n",
      "Epoch 1/70\n",
      "67/67 [==============================] - 130s 2s/step - loss: 2.3088 - accuracy: 0.1243 - val_loss: 2.3029 - val_accuracy: 0.1520\n",
      "Epoch 2/70\n",
      "67/67 [==============================] - 137s 2s/step - loss: 2.2221 - accuracy: 0.1684 - val_loss: 2.1401 - val_accuracy: 0.1839\n",
      "Epoch 3/70\n",
      "67/67 [==============================] - 116s 2s/step - loss: 2.0476 - accuracy: 0.2233 - val_loss: 2.0453 - val_accuracy: 0.2064\n",
      "Epoch 4/70\n",
      "67/67 [==============================] - 130s 2s/step - loss: 1.8862 - accuracy: 0.2706 - val_loss: 1.8477 - val_accuracy: 0.2439\n",
      "Epoch 5/70\n",
      "67/67 [==============================] - 121s 2s/step - loss: 1.7366 - accuracy: 0.3222 - val_loss: 1.8393 - val_accuracy: 0.3227\n",
      "Epoch 6/70\n",
      "67/67 [==============================] - 122s 2s/step - loss: 1.6537 - accuracy: 0.3696 - val_loss: 1.7062 - val_accuracy: 0.3546\n",
      "Epoch 7/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 1.5411 - accuracy: 0.4104 - val_loss: 1.6509 - val_accuracy: 0.3865\n",
      "Epoch 8/70\n",
      "67/67 [==============================] - 126s 2s/step - loss: 1.4128 - accuracy: 0.4540 - val_loss: 1.5942 - val_accuracy: 0.3959\n",
      "Epoch 9/70\n",
      "67/67 [==============================] - 128s 2s/step - loss: 1.3065 - accuracy: 0.5042 - val_loss: 1.5038 - val_accuracy: 0.3996\n",
      "Epoch 10/70\n",
      "67/67 [==============================] - 130s 2s/step - loss: 1.2473 - accuracy: 0.5159 - val_loss: 1.4234 - val_accuracy: 0.4728\n",
      "Epoch 11/70\n",
      "67/67 [==============================] - 124s 2s/step - loss: 1.1017 - accuracy: 0.5755 - val_loss: 1.3628 - val_accuracy: 0.5009\n",
      "Epoch 12/70\n",
      "67/67 [==============================] - 128s 2s/step - loss: 0.9834 - accuracy: 0.6360 - val_loss: 1.3385 - val_accuracy: 0.5159\n",
      "Epoch 13/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.9015 - accuracy: 0.6660 - val_loss: 1.1844 - val_accuracy: 0.5741\n",
      "Epoch 14/70\n",
      "67/67 [==============================] - 132s 2s/step - loss: 0.7846 - accuracy: 0.7214 - val_loss: 1.1397 - val_accuracy: 0.5929\n",
      "Epoch 15/70\n",
      "67/67 [==============================] - 127s 2s/step - loss: 0.6550 - accuracy: 0.7514 - val_loss: 1.2388 - val_accuracy: 0.5741\n",
      "Epoch 16/70\n",
      "67/67 [==============================] - 128s 2s/step - loss: 0.5319 - accuracy: 0.8058 - val_loss: 1.1936 - val_accuracy: 0.5929\n",
      "Epoch 17/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.5127 - accuracy: 0.8213 - val_loss: 1.0759 - val_accuracy: 0.6360\n",
      "Epoch 18/70\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.4108 - accuracy: 0.8513 - val_loss: 1.1383 - val_accuracy: 0.6435\n",
      "Epoch 19/70\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.4660 - accuracy: 0.8405 - val_loss: 0.9718 - val_accuracy: 0.6904\n",
      "Epoch 20/70\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.3280 - accuracy: 0.8795 - val_loss: 1.0288 - val_accuracy: 0.6829\n",
      "Epoch 21/70\n",
      "67/67 [==============================] - 128s 2s/step - loss: 0.2502 - accuracy: 0.9142 - val_loss: 1.1688 - val_accuracy: 0.6961\n",
      "Epoch 22/70\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.3227 - accuracy: 0.8799 - val_loss: 1.0813 - val_accuracy: 0.6848\n",
      "Epoch 23/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.2659 - accuracy: 0.9067 - val_loss: 1.0190 - val_accuracy: 0.7205\n",
      "Epoch 24/70\n",
      "67/67 [==============================] - 99s 1s/step - loss: 0.2307 - accuracy: 0.9189 - val_loss: 1.1494 - val_accuracy: 0.6961\n",
      "Epoch 25/70\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.1945 - accuracy: 0.9311 - val_loss: 1.2682 - val_accuracy: 0.6792\n",
      "Epoch 26/70\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.1738 - accuracy: 0.9423 - val_loss: 1.2224 - val_accuracy: 0.6942\n",
      "Epoch 27/70\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.2062 - accuracy: 0.9278 - val_loss: 1.3050 - val_accuracy: 0.6867\n",
      "Epoch 28/70\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.1802 - accuracy: 0.9400 - val_loss: 1.1377 - val_accuracy: 0.7298\n",
      "Epoch 29/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.1330 - accuracy: 0.9526 - val_loss: 1.3430 - val_accuracy: 0.7036\n",
      "Epoch 30/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.1600 - accuracy: 0.9442 - val_loss: 1.2126 - val_accuracy: 0.7148\n",
      "Epoch 31/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.1714 - accuracy: 0.9484 - val_loss: 1.2808 - val_accuracy: 0.7017\n",
      "Epoch 32/70\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.1373 - accuracy: 0.9578 - val_loss: 1.3652 - val_accuracy: 0.7017\n",
      "Epoch 33/70\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.0769 - accuracy: 0.9784 - val_loss: 1.1298 - val_accuracy: 0.7617\n",
      "Epoch 34/70\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0558 - accuracy: 0.9841 - val_loss: 1.2819 - val_accuracy: 0.7242\n",
      "Epoch 35/70\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0491 - accuracy: 0.9855 - val_loss: 1.4924 - val_accuracy: 0.7017\n",
      "Epoch 36/70\n",
      "67/67 [==============================] - 111s 2s/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: 1.4174 - val_accuracy: 0.7073\n",
      "Epoch 37/70\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.1802 - accuracy: 0.9418 - val_loss: 1.2779 - val_accuracy: 0.7205\n",
      "Epoch 38/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.2770 - accuracy: 0.9165 - val_loss: 1.2887 - val_accuracy: 0.6979\n",
      "Epoch 39/70\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.1564 - accuracy: 0.9470 - val_loss: 1.0656 - val_accuracy: 0.7448\n",
      "Epoch 40/70\n",
      "67/67 [==============================] - 89s 1s/step - loss: 0.0673 - accuracy: 0.9728 - val_loss: 1.1136 - val_accuracy: 0.7542\n",
      "Epoch 41/70\n",
      "67/67 [==============================] - 92s 1s/step - loss: 0.1031 - accuracy: 0.9667 - val_loss: 1.1618 - val_accuracy: 0.7523\n",
      "Epoch 42/70\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0878 - accuracy: 0.9714 - val_loss: 1.1107 - val_accuracy: 0.7598\n",
      "Epoch 43/70\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.0839 - accuracy: 0.9737 - val_loss: 1.1192 - val_accuracy: 0.7617\n",
      "Epoch 44/70\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0742 - accuracy: 0.9709 - val_loss: 1.1001 - val_accuracy: 0.7617\n",
      "Epoch 45/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 1.2225 - val_accuracy: 0.7598\n",
      "Epoch 46/70\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.0721 - accuracy: 0.9789 - val_loss: 1.2110 - val_accuracy: 0.7542\n",
      "Epoch 47/70\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0811 - accuracy: 0.9723 - val_loss: 1.2268 - val_accuracy: 0.7580\n",
      "Epoch 48/70\n",
      "67/67 [==============================] - 97s 1s/step - loss: 0.0889 - accuracy: 0.9723 - val_loss: 1.3384 - val_accuracy: 0.7148\n",
      "Epoch 49/70\n",
      "67/67 [==============================] - 98s 1s/step - loss: 0.1064 - accuracy: 0.9700 - val_loss: 1.1019 - val_accuracy: 0.7580\n",
      "Epoch 50/70\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.1190 - accuracy: 0.9564 - val_loss: 1.0645 - val_accuracy: 0.7561\n",
      "Epoch 51/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.0622 - accuracy: 0.9812 - val_loss: 1.1601 - val_accuracy: 0.7692\n",
      "Epoch 52/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 1.0763 - val_accuracy: 0.7917\n",
      "Epoch 53/70\n",
      "67/67 [==============================] - 111s 2s/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 1.1173 - val_accuracy: 0.7880\n",
      "Epoch 54/70\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 1.2358 - val_accuracy: 0.7674\n",
      "Epoch 55/70\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 1.2016 - val_accuracy: 0.7824\n",
      "Epoch 56/70\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 1.2133 - val_accuracy: 0.7805\n",
      "Epoch 57/70\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 1.2441 - val_accuracy: 0.7824\n",
      "Epoch 58/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 1.2408 - val_accuracy: 0.7861\n",
      "Epoch 59/70\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 1.2675 - val_accuracy: 0.7842\n",
      "Epoch 60/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0885 - accuracy: 0.9812 - val_loss: 1.3233 - val_accuracy: 0.7505\n",
      "Epoch 61/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.2417 - accuracy: 0.9231 - val_loss: 1.1345 - val_accuracy: 0.7336\n",
      "Epoch 62/70\n",
      "67/67 [==============================] - 92s 1s/step - loss: 0.1168 - accuracy: 0.9639 - val_loss: 1.1756 - val_accuracy: 0.7561\n",
      "Epoch 63/70\n",
      "67/67 [==============================] - 102s 2s/step - loss: 0.0997 - accuracy: 0.9676 - val_loss: 1.2385 - val_accuracy: 0.7580\n",
      "Epoch 64/70\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.0667 - accuracy: 0.9784 - val_loss: 1.1411 - val_accuracy: 0.7899\n",
      "Epoch 65/70\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0854 - accuracy: 0.9728 - val_loss: 1.1033 - val_accuracy: 0.7749\n",
      "Epoch 66/70\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.1102 - accuracy: 0.9662 - val_loss: 1.1105 - val_accuracy: 0.7786\n",
      "Epoch 67/70\n",
      "67/67 [==============================] - 101s 1s/step - loss: 0.1427 - accuracy: 0.9545 - val_loss: 1.1325 - val_accuracy: 0.7805\n",
      "Epoch 68/70\n",
      "67/67 [==============================] - 97s 1s/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 1.0801 - val_accuracy: 0.7899\n",
      "Epoch 69/70\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 1.0500 - val_accuracy: 0.7880\n",
      "Epoch 70/70\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.0269 - accuracy: 0.9944 - val_loss: 1.0549 - val_accuracy: 0.8011\n",
      "17/17 [==============================] - 4s 264ms/step - loss: 1.0549 - accuracy: 0.8011\n",
      " Test accuracy: 0.801125705242157\n"
     ]
    }
   ],
   "source": [
    "def create_model(lstm_num,dense_num):\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(lstm_num, return_sequences=True)(input_layer) #512, 256, 128, 100 \n",
    "    x = Dropout(0.1)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(lstm_num)(x) # \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(dense_num, activation='relu')(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "     \n",
    "    return model\n",
    " \n",
    "print(f'Testing model with LSTM units: {150} and Dense units: {300}')\n",
    "model = create_model(150, 300)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=32, verbose=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0) \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f' Test accuracy: {test_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c64ab-6b87-40de-a581-b955124565c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf9bfa-20a7-40fc-8b60-66f03e128741",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5439a0c1-90a9-43f0-81da-a726337fdf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with LSTM units: 64 and Dense units: 128\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 100, 42)]         0         \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 100, 64)           27392     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 100, 64)           0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,026\n",
      "Trainable params: 70,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "67/67 [==============================] - 31s 348ms/step - loss: 2.2976 - accuracy: 0.1252 - val_loss: 2.2862 - val_accuracy: 0.1276\n",
      "Epoch 2/70\n",
      "67/67 [==============================] - 21s 320ms/step - loss: 2.2414 - accuracy: 0.1693 - val_loss: 2.2631 - val_accuracy: 0.1764\n",
      "Epoch 3/70\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 2.2081 - accuracy: 0.1707 - val_loss: 2.1778 - val_accuracy: 0.1876\n",
      "Epoch 4/70\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 2.0929 - accuracy: 0.2265 - val_loss: 2.0941 - val_accuracy: 0.2120\n",
      "Epoch 5/70\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 2.0356 - accuracy: 0.2472 - val_loss: 2.0202 - val_accuracy: 0.2514\n",
      "Epoch 6/70\n",
      "67/67 [==============================] - 21s 306ms/step - loss: 1.9858 - accuracy: 0.2744 - val_loss: 2.0036 - val_accuracy: 0.2477\n",
      "Epoch 7/70\n",
      "67/67 [==============================] - 22s 321ms/step - loss: 1.8743 - accuracy: 0.3063 - val_loss: 1.9409 - val_accuracy: 0.2758\n",
      "Epoch 8/70\n",
      "67/67 [==============================] - 21s 321ms/step - loss: 1.7864 - accuracy: 0.3335 - val_loss: 1.8817 - val_accuracy: 0.2720\n",
      "Epoch 9/70\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 1.7916 - accuracy: 0.3161 - val_loss: 1.8492 - val_accuracy: 0.3021\n",
      "Epoch 10/70\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 1.7203 - accuracy: 0.3579 - val_loss: 1.8101 - val_accuracy: 0.3077\n",
      "Epoch 11/70\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 1.6611 - accuracy: 0.3654 - val_loss: 1.7802 - val_accuracy: 0.3152\n",
      "Epoch 12/70\n",
      "67/67 [==============================] - 24s 359ms/step - loss: 1.5697 - accuracy: 0.4132 - val_loss: 1.6966 - val_accuracy: 0.3433\n",
      "Epoch 13/70\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 1.4332 - accuracy: 0.4536 - val_loss: 1.7040 - val_accuracy: 0.3659\n",
      "Epoch 14/70\n",
      "67/67 [==============================] - 22s 328ms/step - loss: 1.3727 - accuracy: 0.4554 - val_loss: 1.6232 - val_accuracy: 0.3921\n",
      "Epoch 15/70\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 1.2899 - accuracy: 0.5009 - val_loss: 1.5977 - val_accuracy: 0.4146\n",
      "Epoch 16/70\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 1.2679 - accuracy: 0.5070 - val_loss: 1.6135 - val_accuracy: 0.3865\n",
      "Epoch 17/70\n",
      "67/67 [==============================] - 22s 335ms/step - loss: 1.2179 - accuracy: 0.5235 - val_loss: 1.5150 - val_accuracy: 0.4278\n",
      "Epoch 18/70\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 1.1459 - accuracy: 0.5605 - val_loss: 1.5002 - val_accuracy: 0.4334\n",
      "Epoch 19/70\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 1.0711 - accuracy: 0.5976 - val_loss: 1.4854 - val_accuracy: 0.4503\n",
      "Epoch 20/70\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.9897 - accuracy: 0.6210 - val_loss: 1.4376 - val_accuracy: 0.4953\n",
      "Epoch 21/70\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 0.9406 - accuracy: 0.6295 - val_loss: 1.4423 - val_accuracy: 0.5047\n",
      "Epoch 22/70\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.8977 - accuracy: 0.6660 - val_loss: 1.4472 - val_accuracy: 0.5141\n",
      "Epoch 23/70\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.8787 - accuracy: 0.6735 - val_loss: 1.3727 - val_accuracy: 0.5347\n",
      "Epoch 24/70\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 0.8088 - accuracy: 0.7036 - val_loss: 1.4030 - val_accuracy: 0.5122\n",
      "Epoch 25/70\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.8543 - accuracy: 0.6787 - val_loss: 1.3105 - val_accuracy: 0.5535\n",
      "Epoch 26/70\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.7048 - accuracy: 0.7294 - val_loss: 1.4525 - val_accuracy: 0.5272\n",
      "Epoch 27/70\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.7112 - accuracy: 0.7270 - val_loss: 1.3439 - val_accuracy: 0.5535\n",
      "Epoch 28/70\n",
      "67/67 [==============================] - 22s 329ms/step - loss: 0.6703 - accuracy: 0.7523 - val_loss: 1.3840 - val_accuracy: 0.5535\n",
      "Epoch 29/70\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 0.5836 - accuracy: 0.7814 - val_loss: 1.4927 - val_accuracy: 0.5084\n",
      "Epoch 30/70\n",
      "67/67 [==============================] - 24s 351ms/step - loss: 0.6530 - accuracy: 0.7589 - val_loss: 1.3535 - val_accuracy: 0.5629\n",
      "Epoch 31/70\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.5654 - accuracy: 0.7871 - val_loss: 1.5208 - val_accuracy: 0.5328\n",
      "Epoch 32/70\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.5401 - accuracy: 0.8016 - val_loss: 1.3732 - val_accuracy: 0.5872\n",
      "Epoch 33/70\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.5901 - accuracy: 0.7814 - val_loss: 1.3146 - val_accuracy: 0.5797\n",
      "Epoch 34/70\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.4633 - accuracy: 0.8265 - val_loss: 1.4541 - val_accuracy: 0.5872\n",
      "Epoch 35/70\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.4360 - accuracy: 0.8363 - val_loss: 1.4458 - val_accuracy: 0.5929\n",
      "Epoch 36/70\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.4557 - accuracy: 0.8297 - val_loss: 1.3659 - val_accuracy: 0.5760\n",
      "Epoch 37/70\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.4448 - accuracy: 0.8307 - val_loss: 1.3102 - val_accuracy: 0.6004\n",
      "Epoch 38/70\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.4138 - accuracy: 0.8419 - val_loss: 1.3811 - val_accuracy: 0.5910\n",
      "Epoch 39/70\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.3658 - accuracy: 0.8724 - val_loss: 1.5483 - val_accuracy: 0.5910\n",
      "Epoch 40/70\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.3818 - accuracy: 0.8569 - val_loss: 1.4335 - val_accuracy: 0.5854\n",
      "Epoch 41/70\n",
      "67/67 [==============================] - 22s 333ms/step - loss: 0.3845 - accuracy: 0.8602 - val_loss: 1.3856 - val_accuracy: 0.5854\n",
      "Epoch 42/70\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 0.3840 - accuracy: 0.8555 - val_loss: 1.4105 - val_accuracy: 0.6116\n",
      "Epoch 43/70\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.3291 - accuracy: 0.8837 - val_loss: 1.4916 - val_accuracy: 0.6154\n",
      "Epoch 44/70\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 0.3860 - accuracy: 0.8541 - val_loss: 1.4563 - val_accuracy: 0.6079\n",
      "Epoch 45/70\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.2955 - accuracy: 0.8907 - val_loss: 1.4258 - val_accuracy: 0.6098\n",
      "Epoch 46/70\n",
      "67/67 [==============================] - 23s 351ms/step - loss: 0.3138 - accuracy: 0.8865 - val_loss: 1.5333 - val_accuracy: 0.5947\n",
      "Epoch 47/70\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.2451 - accuracy: 0.9104 - val_loss: 1.4776 - val_accuracy: 0.6060\n",
      "Epoch 48/70\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.2539 - accuracy: 0.9132 - val_loss: 1.4404 - val_accuracy: 0.6135\n",
      "Epoch 49/70\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.2131 - accuracy: 0.9217 - val_loss: 1.5762 - val_accuracy: 0.6210\n",
      "Epoch 50/70\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.1934 - accuracy: 0.9320 - val_loss: 1.6228 - val_accuracy: 0.6229\n",
      "Epoch 51/70\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.2073 - accuracy: 0.9235 - val_loss: 1.5707 - val_accuracy: 0.6173\n",
      "Epoch 52/70\n",
      "67/67 [==============================] - 22s 336ms/step - loss: 0.2881 - accuracy: 0.9024 - val_loss: 1.5984 - val_accuracy: 0.6079\n",
      "Epoch 53/70\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.2051 - accuracy: 0.9325 - val_loss: 1.5745 - val_accuracy: 0.6116\n",
      "Epoch 54/70\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1545 - accuracy: 0.9489 - val_loss: 1.6382 - val_accuracy: 0.6154\n",
      "Epoch 55/70\n",
      "67/67 [==============================] - 23s 347ms/step - loss: 0.1459 - accuracy: 0.9512 - val_loss: 1.6208 - val_accuracy: 0.6341\n",
      "Epoch 56/70\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.2338 - accuracy: 0.9170 - val_loss: 1.7571 - val_accuracy: 0.5985\n",
      "Epoch 57/70\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 0.3205 - accuracy: 0.8874 - val_loss: 1.6838 - val_accuracy: 0.6229\n",
      "Epoch 58/70\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.3317 - accuracy: 0.8809 - val_loss: 1.4657 - val_accuracy: 0.6323\n",
      "Epoch 59/70\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.2062 - accuracy: 0.9343 - val_loss: 1.4132 - val_accuracy: 0.6548\n",
      "Epoch 60/70\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 0.1843 - accuracy: 0.9348 - val_loss: 1.4823 - val_accuracy: 0.6454\n",
      "Epoch 61/70\n",
      "67/67 [==============================] - 24s 355ms/step - loss: 0.1870 - accuracy: 0.9315 - val_loss: 1.3795 - val_accuracy: 0.6679\n",
      "Epoch 62/70\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.1596 - accuracy: 0.9512 - val_loss: 1.5975 - val_accuracy: 0.6360\n",
      "Epoch 63/70\n",
      "67/67 [==============================] - 23s 349ms/step - loss: 0.1736 - accuracy: 0.9456 - val_loss: 1.5944 - val_accuracy: 0.6454\n",
      "Epoch 64/70\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.1151 - accuracy: 0.9639 - val_loss: 1.6136 - val_accuracy: 0.6623\n",
      "Epoch 65/70\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 0.0982 - accuracy: 0.9733 - val_loss: 1.7579 - val_accuracy: 0.6266\n",
      "Epoch 66/70\n",
      "67/67 [==============================] - 24s 354ms/step - loss: 0.2069 - accuracy: 0.9371 - val_loss: 1.5702 - val_accuracy: 0.6492\n",
      "Epoch 67/70\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 0.1430 - accuracy: 0.9498 - val_loss: 1.7758 - val_accuracy: 0.6473\n",
      "Epoch 68/70\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.1257 - accuracy: 0.9611 - val_loss: 1.6015 - val_accuracy: 0.6642\n",
      "Epoch 69/70\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 0.1268 - accuracy: 0.9606 - val_loss: 1.6933 - val_accuracy: 0.6492\n",
      "Epoch 70/70\n",
      "67/67 [==============================] - 23s 341ms/step - loss: 0.1733 - accuracy: 0.9451 - val_loss: 1.6439 - val_accuracy: 0.6417\n",
      "Validation Loss: 1.6439498662948608, Validation Accuracy: 0.6416510343551636\n"
     ]
    }
   ],
   "source": [
    "def create_model(lstm_num,dense_num):\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(lstm_num, return_sequences=True)(input_layer) #512, 256, 128, 100 \n",
    "    x = Dropout(0.1)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(lstm_num)(x) # \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(dense_num, activation='relu')(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    " \n",
    "print(f'Testing model with LSTM units: {64} and Dense units: {128}')\n",
    "model = create_model(64, 128)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=32, verbose=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}') \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f' Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e127aef-e600-48e8-a4ba-3105d77b7a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2afe9-8bd3-45a3-9a32-9eeeced11e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = load_model('audio_classification_model.h5')\n",
    "\n",
    "def predict_audio_class(model, file_path, n_mfcc=42, max_pad_len=100):\n",
    "   # Extract features from the new audio file\n",
    "   features = extract_features(file_path, n_mfcc, max_pad_len)\n",
    "   \n",
    "   # Reshape to match the input shape of the model\n",
    "   features = np.expand_dims(features, axis=0)  # Add batch dimension\n",
    "   features = np.expand_dims(features, axis=-1) # Add channel dimension\n",
    "   \n",
    "   # Make a prediction\n",
    "   predictions = model.predict(features)\n",
    "   \n",
    "   # Get the predicted class\n",
    "   predicted_class = np.argmax(predictions, axis=1)\n",
    "   \n",
    "   return predicted_class\n",
    "# Function to record audio\n",
    "def record_audio(duration=5, sample_rate=22050, file_path='recorded_audio.wav'):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording finished\")\n",
    "    wavio.write(file_path, recording, sample_rate, sampwidth=2)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# Record and test the model with a new audio file\n",
    "file_path = record_audio()\n",
    "predicted_class = predict_audio_class(model, file_path)\n",
    "print(f'The predicted class is: {classes[predicted_class[0]]}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b7e89f-7307-46dc-bfc7-e402b27e90f5",
   "metadata": {},
   "source": [
    "a 30  150 and Dense units: 300 lemporte avc 0.7279549837112427\n",
    "aallons a 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0302b-d70b-4779-848f-e1211ce8a530",
   "metadata": {},
   "source": [
    "A lepoch 70 Testing model with LSTM units: 150 and Dense units: 300 avec un score de 0.801125705242157\n",
    "Nous garderons alors cette configuration et allons monter juska 130 pour voir le resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3c4315-f1fe-4bd1-bedf-342ee10cd2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with LSTM units: 150 and Dense units: 300\n",
      "Epoch 1/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 2.3012 - accuracy: 0.1262 - val_loss: 2.2790 - val_accuracy: 0.1445\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 101s 2s/step - loss: 2.1644 - accuracy: 0.1839 - val_loss: 2.1094 - val_accuracy: 0.2083\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 2.0075 - accuracy: 0.2402 - val_loss: 1.9136 - val_accuracy: 0.2570\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 108s 2s/step - loss: 1.8914 - accuracy: 0.2838 - val_loss: 1.9492 - val_accuracy: 0.2627\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 1.7600 - accuracy: 0.3232 - val_loss: 1.9116 - val_accuracy: 0.2402\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 1.6174 - accuracy: 0.3813 - val_loss: 1.7011 - val_accuracy: 0.3396\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 112s 2s/step - loss: 1.5788 - accuracy: 0.3827 - val_loss: 1.6943 - val_accuracy: 0.3659\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 111s 2s/step - loss: 1.4697 - accuracy: 0.4357 - val_loss: 1.7044 - val_accuracy: 0.3527\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 1.3942 - accuracy: 0.4794 - val_loss: 1.7393 - val_accuracy: 0.3790\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 114s 2s/step - loss: 1.2224 - accuracy: 0.5305 - val_loss: 1.5107 - val_accuracy: 0.4597\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 114s 2s/step - loss: 1.1819 - accuracy: 0.5614 - val_loss: 1.5636 - val_accuracy: 0.4484\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.0537 - accuracy: 0.6065 - val_loss: 1.6158 - val_accuracy: 0.4465\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.9370 - accuracy: 0.6417 - val_loss: 1.3548 - val_accuracy: 0.5197\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8431 - accuracy: 0.6923 - val_loss: 1.3161 - val_accuracy: 0.5722\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.7193 - accuracy: 0.7383 - val_loss: 1.3042 - val_accuracy: 0.5685\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.6853 - accuracy: 0.7481 - val_loss: 1.4143 - val_accuracy: 0.5741\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.6827 - accuracy: 0.7533 - val_loss: 1.3098 - val_accuracy: 0.5854\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.6264 - accuracy: 0.7814 - val_loss: 1.3030 - val_accuracy: 0.5854\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.4970 - accuracy: 0.8213 - val_loss: 1.3718 - val_accuracy: 0.6135\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.4858 - accuracy: 0.8274 - val_loss: 1.3759 - val_accuracy: 0.6154\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.3918 - accuracy: 0.8593 - val_loss: 1.3165 - val_accuracy: 0.6266\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.4144 - accuracy: 0.8480 - val_loss: 1.3682 - val_accuracy: 0.6173\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.4250 - accuracy: 0.8485 - val_loss: 1.3497 - val_accuracy: 0.6098\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.3201 - accuracy: 0.8856 - val_loss: 1.3258 - val_accuracy: 0.6417\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.2490 - accuracy: 0.9114 - val_loss: 1.3458 - val_accuracy: 0.6492\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.2349 - accuracy: 0.9095 - val_loss: 1.4963 - val_accuracy: 0.6341\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.2888 - accuracy: 0.9006 - val_loss: 1.5778 - val_accuracy: 0.6304\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.2246 - accuracy: 0.9282 - val_loss: 1.5085 - val_accuracy: 0.6567\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.1874 - accuracy: 0.9325 - val_loss: 1.6218 - val_accuracy: 0.6398\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.1983 - accuracy: 0.9357 - val_loss: 1.5252 - val_accuracy: 0.6604\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.1314 - accuracy: 0.9573 - val_loss: 1.8400 - val_accuracy: 0.6417\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.1848 - accuracy: 0.9400 - val_loss: 1.4482 - val_accuracy: 0.6923\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.1321 - accuracy: 0.9597 - val_loss: 1.6041 - val_accuracy: 0.6829\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.1567 - accuracy: 0.9508 - val_loss: 1.5549 - val_accuracy: 0.6642\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.2590 - accuracy: 0.9189 - val_loss: 1.5080 - val_accuracy: 0.6642\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.1880 - accuracy: 0.9348 - val_loss: 1.5159 - val_accuracy: 0.6735\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.1435 - accuracy: 0.9437 - val_loss: 1.4420 - val_accuracy: 0.6979\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.1643 - accuracy: 0.9451 - val_loss: 1.5745 - val_accuracy: 0.6604\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.1699 - accuracy: 0.9428 - val_loss: 1.4202 - val_accuracy: 0.6904\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0914 - accuracy: 0.9728 - val_loss: 1.4075 - val_accuracy: 0.7073\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 1.4495 - val_accuracy: 0.7167\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0717 - accuracy: 0.9789 - val_loss: 1.5817 - val_accuracy: 0.6886\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.1927 - accuracy: 0.9432 - val_loss: 1.6445 - val_accuracy: 0.6229\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.1695 - accuracy: 0.9447 - val_loss: 1.4146 - val_accuracy: 0.6923\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.1081 - accuracy: 0.9662 - val_loss: 1.4781 - val_accuracy: 0.7111\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0800 - accuracy: 0.9756 - val_loss: 1.5369 - val_accuracy: 0.6961\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0876 - accuracy: 0.9728 - val_loss: 1.4849 - val_accuracy: 0.6998\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0629 - accuracy: 0.9803 - val_loss: 1.5133 - val_accuracy: 0.7092\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.0619 - accuracy: 0.9836 - val_loss: 1.6999 - val_accuracy: 0.6698\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.1219 - accuracy: 0.9601 - val_loss: 1.5337 - val_accuracy: 0.7017\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.1762 - accuracy: 0.9447 - val_loss: 1.3479 - val_accuracy: 0.7017\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.1235 - accuracy: 0.9634 - val_loss: 1.4080 - val_accuracy: 0.6979\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0671 - accuracy: 0.9756 - val_loss: 1.4547 - val_accuracy: 0.7355\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0814 - accuracy: 0.9794 - val_loss: 1.4171 - val_accuracy: 0.7092\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 1.7407 - val_accuracy: 0.6698\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.1022 - accuracy: 0.9719 - val_loss: 1.4910 - val_accuracy: 0.7129\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0769 - accuracy: 0.9737 - val_loss: 1.5653 - val_accuracy: 0.7129\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.1278 - accuracy: 0.9648 - val_loss: 1.4749 - val_accuracy: 0.6848\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0873 - accuracy: 0.9723 - val_loss: 1.4555 - val_accuracy: 0.7167\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.0688 - accuracy: 0.9775 - val_loss: 1.4946 - val_accuracy: 0.6942\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.0550 - accuracy: 0.9841 - val_loss: 1.6011 - val_accuracy: 0.6904\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0470 - accuracy: 0.9859 - val_loss: 1.5822 - val_accuracy: 0.7073\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.0897 - accuracy: 0.9705 - val_loss: 1.6157 - val_accuracy: 0.6979\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0477 - accuracy: 0.9869 - val_loss: 1.5045 - val_accuracy: 0.7205\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 1.4374 - val_accuracy: 0.7205\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 1.5892 - val_accuracy: 0.7092\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 1.5972 - val_accuracy: 0.7092\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 1.6742 - val_accuracy: 0.7036\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0594 - accuracy: 0.9850 - val_loss: 1.5217 - val_accuracy: 0.7148\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.0425 - accuracy: 0.9850 - val_loss: 1.5256 - val_accuracy: 0.7054\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 1.8193 - val_accuracy: 0.6979\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0986 - accuracy: 0.9700 - val_loss: 1.5082 - val_accuracy: 0.7111\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.0903 - accuracy: 0.9719 - val_loss: 1.5203 - val_accuracy: 0.7223\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 1.5884 - val_accuracy: 0.7111\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 1.5862 - val_accuracy: 0.7298\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 1.6268 - val_accuracy: 0.7205\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 1.2192 - val_accuracy: 0.7448\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 104s 2s/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 1.3351 - val_accuracy: 0.7373\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 1.4063 - val_accuracy: 0.7430\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.6703 - val_accuracy: 0.7148\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 1.6193 - val_accuracy: 0.7280\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0575 - accuracy: 0.9845 - val_loss: 1.6831 - val_accuracy: 0.6942\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 103s 2s/step - loss: 0.0802 - accuracy: 0.9789 - val_loss: 1.5523 - val_accuracy: 0.7280\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0556 - accuracy: 0.9817 - val_loss: 1.5573 - val_accuracy: 0.7261\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.1578 - accuracy: 0.9536 - val_loss: 1.3345 - val_accuracy: 0.7148\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.1459 - accuracy: 0.9545 - val_loss: 1.2858 - val_accuracy: 0.7036\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.1140 - accuracy: 0.9592 - val_loss: 1.2836 - val_accuracy: 0.7111\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.0659 - accuracy: 0.9845 - val_loss: 1.3502 - val_accuracy: 0.7336\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 1.3773 - val_accuracy: 0.7373\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 1.4985 - val_accuracy: 0.7336\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0977 - accuracy: 0.9700 - val_loss: 1.3916 - val_accuracy: 0.7205\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 1.2278 - val_accuracy: 0.7523\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 1.3544 - val_accuracy: 0.7486\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 111s 2s/step - loss: 0.0314 - accuracy: 0.9906 - val_loss: 1.4027 - val_accuracy: 0.7580\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 107s 2s/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 1.3791 - val_accuracy: 0.7298\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 109s 2s/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 1.3574 - val_accuracy: 0.7542\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 1.3755 - val_accuracy: 0.7486\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.0609 - accuracy: 0.9826 - val_loss: 1.4195 - val_accuracy: 0.7261\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 111s 2s/step - loss: 0.1226 - accuracy: 0.9587 - val_loss: 1.6185 - val_accuracy: 0.7148\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 106s 2s/step - loss: 0.0932 - accuracy: 0.9681 - val_loss: 1.5308 - val_accuracy: 0.7298\n",
      "17/17 [==============================] - 3s 167ms/step - loss: 1.5308 - accuracy: 0.7298\n",
      " Test accuracy: 0.7298311591148376\n"
     ]
    }
   ],
   "source": [
    "def create_model(lstm_num,dense_num):\n",
    "    # Define the model\n",
    "    input_shape = X_train.shape[1:]  # This should be (num_frames, num_mfcc)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(lstm_num, return_sequences=True)(input_layer) #512, 256, 128, 100 \n",
    "    x = Dropout(0.1)(x) #entre 0.1 et 0.5, aide beaucoup\n",
    "    x = LSTM(lstm_num)(x) # \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(dense_num, activation='relu')(x) \n",
    "    x = Dropout(0.1)(x)\n",
    "    output_layer = Dense(len(classes), activation='softmax')(x)# taille des neurones de sorties\n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "     \n",
    "    return model\n",
    " \n",
    "print(f'Testing model with LSTM units: {150} and Dense units: {300}')\n",
    "model = create_model(150, 300)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0) \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f' Test accuracy: {test_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8093794f-af91-4947-b1f7-fe527cc29e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.0739 - accuracy: 0.9784 - val_loss: 1.3273 - val_accuracy: 0.7430\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.1058 - accuracy: 0.9705 - val_loss: 1.3881 - val_accuracy: 0.7523\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.0717 - accuracy: 0.9765 - val_loss: 1.4349 - val_accuracy: 0.7336\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 1.3212 - val_accuracy: 0.7505\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 1.4224 - val_accuracy: 0.7261\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.1001 - accuracy: 0.9686 - val_loss: 1.2269 - val_accuracy: 0.7448\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 1.3179 - val_accuracy: 0.7467\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 1.1835 - val_accuracy: 0.7767\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 1.2415 - val_accuracy: 0.7880\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 1.3094 - val_accuracy: 0.7842\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3165 - val_accuracy: 0.7842\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.4062 - val_accuracy: 0.7767\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 116s 2s/step - loss: 9.7885e-04 - accuracy: 1.0000 - val_loss: 1.4137 - val_accuracy: 0.7692\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 1.4122 - val_accuracy: 0.7749\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.4172 - val_accuracy: 0.7730\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.7749\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 117s 2s/step - loss: 7.2562e-04 - accuracy: 1.0000 - val_loss: 1.4313 - val_accuracy: 0.7824\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 5.7780e-04 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.7805\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 4.6879e-04 - accuracy: 1.0000 - val_loss: 1.4454 - val_accuracy: 0.7767\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 5.9449e-04 - accuracy: 1.0000 - val_loss: 1.4510 - val_accuracy: 0.7861\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.7067 - val_accuracy: 0.7430\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0689 - accuracy: 0.9812 - val_loss: 1.5931 - val_accuracy: 0.7392\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.1641 - accuracy: 0.9536 - val_loss: 1.2310 - val_accuracy: 0.7392\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0926 - accuracy: 0.9681 - val_loss: 1.2307 - val_accuracy: 0.7636\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 1.3090 - val_accuracy: 0.7598\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0371 - accuracy: 0.9911 - val_loss: 1.3398 - val_accuracy: 0.7636\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0552 - accuracy: 0.9845 - val_loss: 1.3301 - val_accuracy: 0.7392\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0996 - accuracy: 0.9681 - val_loss: 1.2332 - val_accuracy: 0.7373\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 1.2865 - val_accuracy: 0.7674\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 1.3496 - val_accuracy: 0.7261\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 1.2036 - val_accuracy: 0.7730\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 1.2765 - val_accuracy: 0.7786\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.3668 - val_accuracy: 0.7692\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 1.5105 - val_accuracy: 0.7580\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0466 - accuracy: 0.9859 - val_loss: 1.4904 - val_accuracy: 0.7767\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 111s 2s/step - loss: 0.0794 - accuracy: 0.9723 - val_loss: 1.4120 - val_accuracy: 0.7561\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 1.3089 - val_accuracy: 0.7674\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 1.3839 - val_accuracy: 0.7542\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 1.2782 - val_accuracy: 0.7786\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 1.2659 - val_accuracy: 0.7711\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 108s 2s/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 1.4143 - val_accuracy: 0.7655\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 1.4807 - val_accuracy: 0.7598\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 110s 2s/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 1.2877 - val_accuracy: 0.7730\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 1.3274 - val_accuracy: 0.7842\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 1.4955 - val_accuracy: 0.7336\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 1.5466 - val_accuracy: 0.7373\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.0735 - accuracy: 0.9794 - val_loss: 1.3610 - val_accuracy: 0.7561\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0384 - accuracy: 0.9892 - val_loss: 1.3594 - val_accuracy: 0.7580\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 1.3350 - val_accuracy: 0.7674\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 1.3888 - val_accuracy: 0.7617\n",
      "17/17 [==============================] - 4s 264ms/step - loss: 1.3888 - accuracy: 0.7617\n",
      " Test accuracy: 0.7617260813713074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0) \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f' Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a42049-57c1-4985-b411-6734e9fb8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"audio_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e3da00-e531-4ac1-8145-c355c069ed99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
